{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multiclass Image Segmentation with DL\n",
    "\n",
    "Outline\n",
    "\n",
    "1. The Dataset\n",
    "2. Loading all to memory\n",
    "3. Flow from directory\n",
    "\n",
    "In the previous notebook, you trained a U-Net for a single class. But what if there are multiple classes? One approach is to train a binary model for each class. This allows individual optimization for each class, which can be advantageous. Alternatively, you could train a single multiclass model, enabling it to learn inter-class relationships.\n",
    "\n",
    "Both approaches have their pros and cons, so the best strategy is to try both and compare their performance to decide which works best for your use case.\n",
    "\n",
    "In this notebook, I will adjust the network from the previous notebook to make it multi-class. We also need a dataset, as blood cell dataset is binary. I simulated a simple multi-class dataset for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the code, I wanted to create a very simple dataset. Each image contains a triangle and a rectangle. Masks are single channel labeled images where 0 is the background, 1 is the rectangle and 2 is the triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlap(rect1, rect2):\n",
    "    if (rect1[0] < rect2[0] + rect2[2]) and (rect1[0] + rect1[2] > rect2[0]) and \\\n",
    "       (rect1[1] < rect2[1] + rect2[3]) and (rect1[1] + rect1[3] > rect2[1]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def generate_non_overlapping_rect(existing_rects, max_attempts=100):\n",
    "    for _ in range(max_attempts):\n",
    "        x, y = np.random.randint(20, 44, size=2)\n",
    "        size = np.random.randint(10, 20)\n",
    "        new_rect = (x, y, size, size)\n",
    "        if not any(is_overlap(new_rect, rect) for rect in existing_rects):\n",
    "            return new_rect\n",
    "    return None\n",
    "\n",
    "def generate_dataset(num_images, output_dir, dataset_type):\n",
    "    for subdir in [f'{dataset_type}_images/{dataset_type}', f'{dataset_type}_masks/{dataset_type}']:\n",
    "        os.makedirs(os.path.join(output_dir, subdir), exist_ok=True)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        image = np.zeros((64, 64, 3), dtype=np.uint8)\n",
    "        mask = np.zeros((64, 64), dtype=np.uint8)\n",
    "        existing_rects = []\n",
    "\n",
    "        # Generate a rectangle\n",
    "        rect = generate_non_overlapping_rect(existing_rects)\n",
    "        if rect is not None:\n",
    "            x, y, size, _ = rect\n",
    "            existing_rects.append(rect)\n",
    "            image = cv2.rectangle(image, (x, y), (x + size, y + size), (255, 255, 255), -1)\n",
    "            mask = cv2.rectangle(mask, (x, y), (x + size, y + size), 1, -1)\n",
    "\n",
    "        # Generate a triangle\n",
    "        rect = generate_non_overlapping_rect(existing_rects)\n",
    "        if rect is not None:\n",
    "            x, y, size, _ = rect\n",
    "            points = np.array([[x, y], [x + size, y], [x, y + size]], np.int32)\n",
    "            image = cv2.fillConvexPoly(image, points, (255, 255, 255))\n",
    "            mask = cv2.fillConvexPoly(mask, points, 2)\n",
    "\n",
    "        cv2.imwrite(f'{output_dir}/{dataset_type}_images/{dataset_type}/{i}.png', image)\n",
    "        cv2.imwrite(f'{output_dir}/{dataset_type}_masks/{dataset_type}/{i}.png', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you run this block\n",
    "# it will create a folder where the notebook is\n",
    "# and populate it with the dataset\n",
    "output_dir = 'shapes_dataset'\n",
    "\n",
    "generate_dataset(500, output_dir, 'train')\n",
    "generate_dataset(100, output_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x253c937dc40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEQCAYAAAAQ4xaZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcAElEQVR4nO3dcWzU9f3H8dfVtkcV7mor3NHQQpexFUU2LFJO2Oa0W8OMg1GdGoxoyIzuQKEaXZOJ2+I8otlgLALTOHDZkI0liLgJIXXU6QpIHZvMWWGStLPcodt6V5i9Fvr5/bEftx4U17teP3fXez6Sb2K/3+99++6H8d6Lz/fz/dZhjDECAACwJC/dBQAAgNxC+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWjVj4eOqppzRlyhSNGTNGNTU1OnDgwEh9KwCjBH0DyA2OkfjdLr/85S91xx13aOPGjaqpqdHatWu1bds2tbW1acKECR/72f7+fnV2dmrcuHFyOBypLg3AEBhj1N3drbKyMuXl2ZkgHU7fkOgdQLol1DfMCJg9e7bx+/2xr8+cOWPKyspMIBD4n5/t6OgwktjY2DJg6+joGIkWMajh9A1j6B1sbJmyDaVv5CvFent71draqsbGxti+vLw81dbWqqWl5bzzo9GootFo7GvDL9kFMsa4ceOsfJ9E+4Z04d4xT19RvgpGtmAA5zmtPr2m3w6pb6Q8fHz44Yc6c+aMPB5P3H6Px6N33nnnvPMDgYC++93vproMAClg6/ZFon1DunDvyFeB8h2ED8C6/587GErfSPvTLo2NjQqHw7Gto6Mj3SUByAL0DiB7pXzm47LLLtNFF12kUCgUtz8UCsnr9Z53vtPplNPpTHUZALJIon1DoncA2SzlMx+FhYWqrq5WU1NTbF9/f7+amprk8/lS/e0AjAL0DSC3pHzmQ5IaGhq0ZMkSzZo1S7Nnz9batWt16tQp3XXXXSPx7QCMAvQNIHeMSPi45ZZb9MEHH2jVqlUKBoP67Gc/q127dp23mAwAzqJvALljRF4yNhyRSERutzvdZQCQFA6H5XK50l3GkJztHddqAU+7AGlw2vRpr3YMqW+k/WkXAACQWwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArEo4fLz66qu68cYbVVZWJofDoRdeeCHuuDFGq1at0sSJE1VUVKTa2lodOXIkVfUCyEL0DQADJRw+Tp06pc985jN66qmnBj3+xBNPaN26ddq4caP279+vSy65RHV1derp6Rl2sQCyE30DwED5iX5g/vz5mj9//qDHjDFau3atvv3tb2vBggWSpJ/97GfyeDx64YUXdOuttw6vWgBZib4BYKCUrvk4duyYgsGgamtrY/vcbrdqamrU0tIy6Gei0agikUjcBiB3JNM3JHoHkM1SGj6CwaAkyePxxO33eDyxY+cKBAJyu92xrby8PJUlAchwyfQNid4BZLO0P+3S2NiocDgc2zo6OtJdEoAsQO8AsldKw4fX65UkhUKhuP2hUCh27FxOp1MulytuA5A7kukbEr0DyGYpDR+VlZXyer1qamqK7YtEItq/f798Pl8qvxWAUYK+AeSehJ92OXnypI4ePRr7+tixYzp06JBKSkpUUVGhFStW6LHHHtPUqVNVWVmpRx55RGVlZVq4cGEq6waQRegbAAZKOHwcPHhQX/ziF2NfNzQ0SJKWLFmizZs366GHHtKpU6d09913q6urS/PmzdOuXbs0ZsyY1FUNIKvQNwAM5DDGmHQXMVAkEpHb7U53GQAkhcPhrFlLcbZ3XKsFyncUpLscIOecNn3aqx1D6htpf9oFAADkFsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqxIKH4FAQFdffbXGjRunCRMmaOHChWpra4s7p6enR36/X6WlpRo7dqzq6+sVCoVSWjSA7ELvADBQQuGjublZfr9f+/bt0549e9TX16cvf/nLOnXqVOyclStXaufOndq2bZuam5vV2dmpRYsWpbxwANmD3gFgIIcxxiT74Q8++EATJkxQc3OzPv/5zyscDmv8+PHasmWLbrrpJknSO++8o2nTpqmlpUVz5sz5n9eMRCJyu93JlgQghcLhsFwuV8qvO5K941otUL6jIOU1A/h4p02f9mrHkPrGsNZ8hMNhSVJJSYkkqbW1VX19faqtrY2dU1VVpYqKCrW0tAx6jWg0qkgkErcBGN3oHUBuSzp89Pf3a8WKFZo7d66mT58uSQoGgyosLFRxcXHcuR6PR8FgcNDrBAIBud3u2FZeXp5sSQCyAL0DQNLhw+/36/Dhw9q6deuwCmhsbFQ4HI5tHR0dw7oegMxG7wCQn8yHli1bppdeekmvvvqqJk2aFNvv9XrV29urrq6uuH/BhEIheb3eQa/ldDrldDqTKQNAlqF3AJASnPkwxmjZsmXavn27XnnlFVVWVsYdr66uVkFBgZqammL72tra1N7eLp/Pl5qKAWQdegeAgRKa+fD7/dqyZYt27NihcePGxe7Fut1uFRUVye12a+nSpWpoaFBJSYlcLpeWL18un883pNXqAEYnegeAgRJ61NbhcAy6f9OmTbrzzjsl/edFQQ888ICef/55RaNR1dXVaf369RecOj0Xj9oCmSNVj9ra7B08agukRyKP2g7rPR8jgfABZI6Res/HSCB8AOll7T0fAAAAiSJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArEoofGzYsEEzZsyQy+WSy+WSz+fTyy+/HDve09Mjv9+v0tJSjR07VvX19QqFQikvGkB2oXcAGCg/kZMnTZqk1atXa+rUqTLG6LnnntOCBQv0xz/+UVdccYVWrlyp3/zmN9q2bZvcbreWLVumRYsW6fXXXx+p+pEEY0y6S0iKw+FIdwlIEr1jdDi6Zk66S0jKJ1fuS3cJOIfDDPP/iUpKSvTkk0/qpptu0vjx47VlyxbddNNNkqR33nlH06ZNU0tLi+bMGfx/tNFoVNFoNPZ1JBJReXn5cErC/0D4wFCFw2G5XK4RufZI9Y5rtUD5joIRqTnXET7wcU6bPu3VjiH1jaTXfJw5c0Zbt27VqVOn5PP51Nraqr6+PtXW1sbOqaqqUkVFhVpaWi54nUAgILfbHdsIHsDoRu8AkHD4eOuttzR27Fg5nU7dc8892r59uy6//HIFg0EVFhaquLg47nyPx6NgMHjB6zU2NiocDse2jo6OhH8IAJmP3gHgrITWfEjSpz/9aR06dEjhcFi//vWvtWTJEjU3NyddgNPplNPpTPrzALIDvQPAWQmHj8LCQn3yk5+UJFVXV+uNN97Qj370I91yyy3q7e1VV1dX3L9gQqGQvF5vygoGkJ3oHQDOGvZ7Pvr7+xWNRlVdXa2CggI1NTXFjrW1tam9vV0+n2+43wbAKEPvAHJXQjMfjY2Nmj9/vioqKtTd3a0tW7Zo79692r17t9xut5YuXaqGhgaVlJTI5XJp+fLl8vl8F1ytDiA30DsADJRQ+Dhx4oTuuOMOHT9+XG63WzNmzNDu3bv1pS99SZK0Zs0a5eXlqb6+XtFoVHV1dVq/fv2IFA4ge9A7AAw07Pd8pFokEpHb7U53GaNahv2RDxnv+bBvJN/zkWpnewfv+Rg5vOcDH8fKez4AAACSQfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABg1bDCx+rVq+VwOLRixYrYvp6eHvn9fpWWlmrs2LGqr69XKBQabp0ARgn6BoCkw8cbb7yhn/zkJ5oxY0bc/pUrV2rnzp3atm2bmpub1dnZqUWLFg27UADZj74BQEoyfJw8eVKLFy/WM888o0svvTS2PxwO69lnn9UPf/hDXXfddaqurtamTZv0hz/8Qfv27Rv0WtFoVJFIJG4DMPqksm9I9A4gmyUVPvx+v2644QbV1tbG7W9tbVVfX1/c/qqqKlVUVKilpWXQawUCAbnd7thWXl6eTEkAMlwq+4ZE7wCyWcLhY+vWrXrzzTcVCATOOxYMBlVYWKji4uK4/R6PR8FgcNDrNTY2KhwOx7aOjo5ESwKQ4VLdNyR6B5DN8hM5uaOjQ/fff7/27NmjMWPGpKQAp9Mpp9OZkmsByDwj0TckegeQzRKa+WhtbdWJEyd01VVXKT8/X/n5+Wpubta6deuUn58vj8ej3t5edXV1xX0uFArJ6/Wmsm4AWYK+AeBcCc18XH/99Xrrrbfi9t11112qqqrSww8/rPLychUUFKipqUn19fWSpLa2NrW3t8vn86WuagBZg74B4FwJhY9x48Zp+vTpcfsuueQSlZaWxvYvXbpUDQ0NKikpkcvl0vLly+Xz+TRnzpzUVQ1JkjEm3SVYlcjP63A4RrASJIK+kXl2dx5K8pPJfi7Nbhn6qXVlnx2xMvBfCYWPoVizZo3y8vJUX1+vaDSquro6rV+/PtXfBsAoQt8AcovDZNg/nyORiNxud7rLyAoZ9keXUZj5SI1wOCyXy5XuMobkbO+4VguU7yhIdzkZLfmZj9GPmY/knTZ92qsdQ+ob/G4XAABgVcpvuwDpwEwHgGQw05EezHwAAACrCB8AAMAqbrsga3GrBUAyuNWSfsx8AAAAqwgfAADAKsIHAACwijUfyBqs8QCQDNZ4ZB5mPgAAgFWEDwAAYBW3XZDRuNUCIBncaslszHwAAACrCB8AAMAqwgcAALCKNR/IKKzxAJAM1nhkF2Y+AACAVYQPAABgFbddkHbcagGQDG61ZC9mPgAAgFWEDwAAYBXhAwAAWMWaD1jHGg8AyWCNx+jBzAcAALAqofDxne98Rw6HI26rqqqKHe/p6ZHf71dpaanGjh2r+vp6hUKhlBcNILvQOwAMlPDMxxVXXKHjx4/Httdeey12bOXKldq5c6e2bdum5uZmdXZ2atGiRSktGEB2oncAOCvhNR/5+fnyer3n7Q+Hw3r22We1ZcsWXXfddZKkTZs2adq0adq3b5/mzJkz/GqRtVjnAXoHksE6j9Ep4ZmPI0eOqKysTJ/4xCe0ePFitbe3S5JaW1vV19en2tra2LlVVVWqqKhQS0vLBa8XjUYViUTiNgCjD70DwFkJhY+amhpt3rxZu3bt0oYNG3Ts2DF97nOfU3d3t4LBoAoLC1VcXBz3GY/Ho2AweMFrBgIBud3u2FZeXp7UDwIgc9E7AAyU0G2X+fPnx/57xowZqqmp0eTJk/WrX/1KRUVFSRXQ2NiohoaG2NeRSIQmMgpwmwUD0TswVNxmyQ3DetS2uLhYn/rUp3T06FF5vV719vaqq6sr7pxQKDTofd6znE6nXC5X3AZgdKN3ALltWOHj5MmT+tvf/qaJEyequrpaBQUFampqih1va2tTe3u7fD7fsAsFMHrQO4DcltBtlwcffFA33nijJk+erM7OTj366KO66KKLdNttt8ntdmvp0qVqaGhQSUmJXC6Xli9fLp/Px2p1IMfROwAMlFD4+Pvf/67bbrtN//jHPzR+/HjNmzdP+/bt0/jx4yVJa9asUV5enurr6xWNRlVXV6f169ePSOHILKzxwMehd+BCWOORmxzGGJPuIgaKRCJyu93pLiMrZNIfHeFjdAqHw1mzluJs77hWC5TvKEh3ORltd+ehdJcQQ/gYPU6bPu3VjiH1DX63CwAAsIrfaoukMdsBIBnMdoCZDwAAYBXhAwAAWEX4AAAAVrHmA0PGGg8AyWCNB87FzAcAALCK8AEAAKzitgs+FrdaACSDWy34OMx8AAAAqwgfAADAKsIHAACwijUfiMMaDwDJYI0HEsHMBwAAsIrwAQAArOK2C7jVAiAp3GpBspj5AAAAVhE+AACAVYQPAABgFWs+chBrPAAkgzUeSBVmPgAAgFWEDwAAYBW3XXIEt1oAJINbLRgJzHwAAACrEg4f77//vm6//XaVlpaqqKhIV155pQ4ePBg7bozRqlWrNHHiRBUVFam2tlZHjhxJadEAsg+9A8BZCYWPf/3rX5o7d64KCgr08ssv6+2339YPfvADXXrppbFznnjiCa1bt04bN27U/v37dckll6iurk49PT0pLx5AdqB3ABjIYYwxQz35W9/6ll5//XX9/ve/H/S4MUZlZWV64IEH9OCDD0qSwuGwPB6PNm/erFtvvfV/fo9IJCK32z3UknLax/3RscYDqRAOh+VyuYZ9HZu941otUL6jYNg1j2a7Ow9d8BhrPJCs06ZPe7VjSH0joZmPF198UbNmzdLNN9+sCRMmaObMmXrmmWdix48dO6ZgMKja2trYPrfbrZqaGrW0tAx6zWg0qkgkErcBGF3oHQAGSih8vPfee9qwYYOmTp2q3bt3695779V9992n5557TpIUDAYlSR6PJ+5zHo8nduxcgUBAbrc7tpWXlyfzcwDIYPQOAAMl9Khtf3+/Zs2apccff1ySNHPmTB0+fFgbN27UkiVLkiqgsbFRDQ0Nsa8jkQhNJEncakGmondkNm61wLaEZj4mTpyoyy+/PG7ftGnT1N7eLknyer2SpFAoFHdOKBSKHTuX0+mUy+WK2wCMLvQOAAMlFD7mzp2rtra2uH3vvvuuJk+eLEmqrKyU1+tVU1NT7HgkEtH+/fvl8/lSUC6AbETvADBQQrddVq5cqWuuuUaPP/64vv71r+vAgQN6+umn9fTTT0v6z7T/ihUr9Nhjj2nq1KmqrKzUI488orKyMi1cuHAk6geQBegdAAZKKHxcffXV2r59uxobG/W9731PlZWVWrt2rRYvXhw756GHHtKpU6d09913q6urS/PmzdOuXbs0ZsyYlBef61jjgWxB78gsrPFAuiX0ng8beM8HkDlS9Z4PG3jPB5BeI/aeDwAAgOEifAAAAKsIHwAAwCrCBwAAsCqhp11syLD1r0BOy6a/j2drPa0+KXvKBkaN0+qTNLS+kXHho7u7O90lAPh/3d3dWfP02dne8Zp+m+ZKgNw2lL6RcY/a9vf3q7OzU8YYVVRUqKOjI2se9bPl7O+wYGziMS6DS2ZcjDHq7u5WWVmZ8vKy4+4svePj8ffjwhibwSU6Lon0jYyb+cjLy9OkSZNivx6b39lwYYzN4BiXwSU6Ltky43EWvWNoGJcLY2wGl8i4DLVvZMc/aQAAwKhB+AAAAFZlbPhwOp169NFH5XQ6011KxmFsBse4DC7XxiXXft6hYlwujLEZ3EiOS8YtOAUAAKNbxs58AACA0YnwAQAArCJ8AAAAqwgfAADAKsIHAACwKmPDx1NPPaUpU6ZozJgxqqmp0YEDB9JdklWBQEBXX321xo0bpwkTJmjhwoVqa2uLO6enp0d+v1+lpaUaO3as6uvrFQqF0lRxeqxevVoOh0MrVqyI7cvlcXn//fd1++23q7S0VEVFRbryyit18ODB2HFjjFatWqWJEyeqqKhItbW1OnLkSBorTi36Bn1jqOgd/5WWvmEy0NatW01hYaH56U9/av7yl7+Yb3zjG6a4uNiEQqF0l2ZNXV2d2bRpkzl8+LA5dOiQ+cpXvmIqKirMyZMnY+fcc889pry83DQ1NZmDBw+aOXPmmGuuuSaNVdt14MABM2XKFDNjxgxz//33x/bn6rj885//NJMnTzZ33nmn2b9/v3nvvffM7t27zdGjR2PnrF692rjdbvPCCy+YP/3pT+arX/2qqaysNB999FEaK08N+gZ9Y6joHf+Vrr6RkeFj9uzZxu/3x74+c+aMKSsrM4FAII1VpdeJEyeMJNPc3GyMMaarq8sUFBSYbdu2xc7561//aiSZlpaWdJVpTXd3t5k6darZs2eP+cIXvhBrILk8Lg8//LCZN2/eBY/39/cbr9drnnzyydi+rq4u43Q6zfPPP2+jxBFF3zgffeN89I546eobGXfbpbe3V62traqtrY3ty8vLU21trVpaWtJYWXqFw2FJUklJiSSptbVVfX19ceNUVVWlioqKnBgnv9+vG264Ie7nl3J7XF588UXNmjVLN998syZMmKCZM2fqmWeeiR0/duyYgsFg3Ni43W7V1NRk/djQNwZH3zgfvSNeuvpGxoWPDz/8UGfOnJHH44nb7/F4FAwG01RVevX392vFihWaO3eupk+fLkkKBoMqLCxUcXFx3Lm5ME5bt27Vm2++qUAgcN6xXB6X9957Txs2bNDUqVO1e/du3Xvvvbrvvvv03HPPSVLs5x+Nf7foG+ejb5yP3nG+dPWN/ORLhi1+v1+HDx/Wa6+9lu5S0q6jo0P333+/9uzZozFjxqS7nIzS39+vWbNm6fHHH5ckzZw5U4cPH9bGjRu1ZMmSNFcH2+gb8egdg0tX38i4mY/LLrtMF1100XkrjEOhkLxeb5qqSp9ly5bppZde0u9+9ztNmjQptt/r9aq3t1ddXV1x54/2cWptbdWJEyd01VVXKT8/X/n5+Wpubta6deuUn58vj8eTk+MiSRMnTtTll18et2/atGlqb2+XpNjPPxr/btE34tE3zkfvGFy6+kbGhY/CwkJVV1erqakptq+/v19NTU3y+XxprMwuY4yWLVum7du365VXXlFlZWXc8erqahUUFMSNU1tbm9rb20f1OF1//fV66623dOjQodg2a9YsLV68OPbfuTgukjR37tzzHqt89913NXnyZElSZWWlvF5v3NhEIhHt378/68eGvvEf9I0Lo3cMLm19I+mlqiNo69atxul0ms2bN5u3337b3H333aa4uNgEg8F0l2bNvffea9xut9m7d685fvx4bPv3v/8dO+eee+4xFRUV5pVXXjEHDx40Pp/P+Hy+NFadHgNXrBuTu+Ny4MABk5+fb77//e+bI0eOmF/84hfm4osvNj//+c9j56xevdoUFxebHTt2mD//+c9mwYIFo+pRW/oGfSMR9I709Y2MDB/GGPPjH//YVFRUmMLCQjN79myzb9++dJdklaRBt02bNsXO+eijj8w3v/lNc+mll5qLL77YfO1rXzPHjx9PX9Fpcm4DyeVx2blzp5k+fbpxOp2mqqrKPP3003HH+/v7zSOPPGI8Ho9xOp3m+uuvN21tbWmqNvXoG/SNRNA7/iMdfcNhjDHJz5sAAAAkJuPWfAAAgNGN8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACr/g/RwJOSBtA3NgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_image = cv2.imread('shapes_dataset/train_images/train/0.png')\n",
    "example_mask = cv2.imread('shapes_dataset/train_masks/train/0.png', 0) # read it as grayscale\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(example_image)\n",
    "ax[1].imshow(example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 255], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(example_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(example_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading all to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME AS NOTEBOOK 7\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *AlMOST* SAME AS NOTEBOOK 7\n",
    "# Diff 1: output layer Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "# Diff 2: loss='categorical_crossentropy'\n",
    "# Diff 3: multiclass_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, n_classes)\n",
    "\n",
    "# U-Net model\n",
    "# Author: Sreenivas Bhattiprolu\n",
    "# This code is coming from the videos at the beginning\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "def multiclass_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, n_classes): # changed\n",
    "# Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    # Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9) # changed\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1]) # changed\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 64, 64, 16)           448       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64, 64, 16)           0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 16)           2320      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 16)           0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)           4640      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 32, 32, 32)           0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 32)           9248      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)           0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 16, 16, 64)           0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 64)           36928     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 128)            73856     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 8, 8, 128)            0         ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 128)            147584    ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 128)            0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 256)            295168    ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 4, 4, 256)            0         ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 256)            590080    ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 8, 8, 128)            131200    ['conv2d_9[0][0]']            \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 8, 8, 256)            0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 128)            295040    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 8, 8, 128)            0         ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)            147584    ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 16, 16, 64)           32832     ['conv2d_11[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 16, 16, 128)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 16, 16, 64)           73792     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 16, 16, 64)           0         ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 64)           36928     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 32, 32, 32)           8224      ['conv2d_13[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 32, 32, 64)           0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 32)           18464     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 32, 32, 32)           0         ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 32, 32, 32)           9248      ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 64, 64, 16)           2064      ['conv2d_15[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 64, 64, 32)           0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 16)           4624      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 64, 64, 16)           0         ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 64, 64, 16)           2320      ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 64, 64, 3)            51        ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1941139 (7.40 MB)\n",
      "Trainable params: 1941139 (7.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multiclass_unet_model(64, 64, 3, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "X_train = []\n",
    "y_train = []\n",
    "for im_path in glob.glob('shapes_dataset/train_images/train/*.png'):\n",
    "    mask_path = im_path.replace('images', 'masks')\n",
    "    im = cv2.imread(im_path)\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    X_train.append(im)\n",
    "    y_train.append(mask)\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "for im_path in glob.glob('shapes_dataset/val_images/val/*.png'):\n",
    "    mask_path = im_path.replace('images', 'masks')\n",
    "    im = cv2.imread(im_path)\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    X_val.append(im)\n",
    "    y_val.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 64, 64, 3), (500, 64, 64), (100, 64, 64, 3), (100, 64, 64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correct mask format for multiclass UNet**\n",
    "\n",
    "One important point is, you need to convert the masks to categorical. Currently it is one channel with all the labels (0, 1, 2). But similar to multiclass classification, we should preprocess this into (1, 0, 0) (0, 1, 0) and (0, 0, 1). You can think of this as color channels, where instead of colors we have binary label masks in each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 64, 64, 3), (100, 64, 64, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_val = to_categorical(y_val, num_classes=3)\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x253f49bf5e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demo of the output format\n",
    "example_mask = y_train[0]\n",
    "rectangle_channel = example_mask[:, :, 1]\n",
    "triangle_channel = example_mask[:, :, 2]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(rectangle_channel)\n",
    "ax[1].imshow(triangle_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I did not normalize the input images. Normally you should. But because this is a simple dataset, it will still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 9s 207ms/step - loss: 8.7356 - accuracy: 0.7356 - f1: 0.6873 - val_loss: 0.4699 - val_accuracy: 0.9619 - val_f1: 0.9554\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 7s 214ms/step - loss: 0.5798 - accuracy: 0.9445 - f1: 0.9509 - val_loss: 0.1166 - val_accuracy: 0.9320 - val_f1: 0.9572\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.1836 - accuracy: 0.9303 - f1: 0.9556 - val_loss: 0.0920 - val_accuracy: 0.9303 - val_f1: 0.9607\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.1375 - accuracy: 0.9310 - f1: 0.9586 - val_loss: 0.0833 - val_accuracy: 0.9334 - val_f1: 0.9628\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 0.1180 - accuracy: 0.9437 - f1: 0.9606 - val_loss: 0.0776 - val_accuracy: 0.9806 - val_f1: 0.9642\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.1043 - accuracy: 0.9764 - f1: 0.9618 - val_loss: 0.0728 - val_accuracy: 0.9814 - val_f1: 0.9652\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.0943 - accuracy: 0.9775 - f1: 0.9627 - val_loss: 0.0695 - val_accuracy: 0.9821 - val_f1: 0.9660\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0870 - accuracy: 0.9782 - f1: 0.9637 - val_loss: 0.0684 - val_accuracy: 0.9822 - val_f1: 0.9661\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.0841 - accuracy: 0.9786 - f1: 0.9638 - val_loss: 0.0679 - val_accuracy: 0.9823 - val_f1: 0.9661\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 0.0811 - accuracy: 0.9791 - f1: 0.9641 - val_loss: 0.0667 - val_accuracy: 0.9829 - val_f1: 0.9667\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 6s 198ms/step - loss: 0.0790 - accuracy: 0.9792 - f1: 0.9644 - val_loss: 0.0658 - val_accuracy: 0.9829 - val_f1: 0.9667\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.0765 - accuracy: 0.9793 - f1: 0.9646 - val_loss: 0.0653 - val_accuracy: 0.9828 - val_f1: 0.9667\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.0754 - accuracy: 0.9795 - f1: 0.9648 - val_loss: 0.0645 - val_accuracy: 0.9830 - val_f1: 0.9669\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 6s 198ms/step - loss: 0.0736 - accuracy: 0.9798 - f1: 0.9649 - val_loss: 0.0635 - val_accuracy: 0.9832 - val_f1: 0.9670\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0726 - accuracy: 0.9798 - f1: 0.9652 - val_loss: 0.0627 - val_accuracy: 0.9831 - val_f1: 0.9669\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.0709 - accuracy: 0.9800 - f1: 0.9653 - val_loss: 0.0621 - val_accuracy: 0.9832 - val_f1: 0.9671\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.0695 - accuracy: 0.9801 - f1: 0.9657 - val_loss: 0.0612 - val_accuracy: 0.9834 - val_f1: 0.9673\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 0.0683 - accuracy: 0.9802 - f1: 0.9663 - val_loss: 0.0598 - val_accuracy: 0.9833 - val_f1: 0.9682\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.0668 - accuracy: 0.9805 - f1: 0.9667 - val_loss: 0.0583 - val_accuracy: 0.9836 - val_f1: 0.9687\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.0662 - accuracy: 0.9805 - f1: 0.9664 - val_loss: 0.0576 - val_accuracy: 0.9835 - val_f1: 0.9686\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0655 - accuracy: 0.9806 - f1: 0.9670 - val_loss: 0.0570 - val_accuracy: 0.9838 - val_f1: 0.9689\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.0643 - accuracy: 0.9807 - f1: 0.9669 - val_loss: 0.0564 - val_accuracy: 0.9838 - val_f1: 0.9690\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.0635 - accuracy: 0.9810 - f1: 0.9670 - val_loss: 0.0558 - val_accuracy: 0.9833 - val_f1: 0.9683\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 0.0624 - accuracy: 0.9813 - f1: 0.9701 - val_loss: 0.0536 - val_accuracy: 0.9848 - val_f1: 0.9847\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.0614 - accuracy: 0.9816 - f1: 0.9816 - val_loss: 0.0539 - val_accuracy: 0.9844 - val_f1: 0.9843\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.0607 - accuracy: 0.9816 - f1: 0.9816 - val_loss: 0.0517 - val_accuracy: 0.9853 - val_f1: 0.9852\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.0595 - accuracy: 0.9821 - f1: 0.9821 - val_loss: 0.0510 - val_accuracy: 0.9857 - val_f1: 0.9855\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0589 - accuracy: 0.9823 - f1: 0.9824 - val_loss: 0.0502 - val_accuracy: 0.9860 - val_f1: 0.9859\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0580 - accuracy: 0.9823 - f1: 0.9824 - val_loss: 0.0495 - val_accuracy: 0.9864 - val_f1: 0.9862\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.0568 - accuracy: 0.9827 - f1: 0.9826 - val_loss: 0.0483 - val_accuracy: 0.9868 - val_f1: 0.9867\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.0564 - accuracy: 0.9829 - f1: 0.9829 - val_loss: 0.0475 - val_accuracy: 0.9870 - val_f1: 0.9869\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.0552 - accuracy: 0.9832 - f1: 0.9833 - val_loss: 0.0468 - val_accuracy: 0.9872 - val_f1: 0.9870\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.0544 - accuracy: 0.9833 - f1: 0.9830 - val_loss: 0.0460 - val_accuracy: 0.9872 - val_f1: 0.9871\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.0535 - accuracy: 0.9835 - f1: 0.9835 - val_loss: 0.0454 - val_accuracy: 0.9872 - val_f1: 0.9870\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.0525 - accuracy: 0.9837 - f1: 0.9836 - val_loss: 0.0449 - val_accuracy: 0.9873 - val_f1: 0.9871\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0517 - accuracy: 0.9838 - f1: 0.9837 - val_loss: 0.0440 - val_accuracy: 0.9873 - val_f1: 0.9871\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.0511 - accuracy: 0.9840 - f1: 0.9837 - val_loss: 0.0438 - val_accuracy: 0.9874 - val_f1: 0.9872\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 0.0504 - accuracy: 0.9841 - f1: 0.9840 - val_loss: 0.0432 - val_accuracy: 0.9874 - val_f1: 0.9872\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.0494 - accuracy: 0.9841 - f1: 0.9843 - val_loss: 0.0426 - val_accuracy: 0.9874 - val_f1: 0.9872\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.0486 - accuracy: 0.9844 - f1: 0.9843 - val_loss: 0.0419 - val_accuracy: 0.9874 - val_f1: 0.9872\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 0.0481 - accuracy: 0.9846 - f1: 0.9845 - val_loss: 0.0414 - val_accuracy: 0.9874 - val_f1: 0.9873\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 0.0475 - accuracy: 0.9847 - f1: 0.9844 - val_loss: 0.0407 - val_accuracy: 0.9874 - val_f1: 0.9873\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 0.0466 - accuracy: 0.9848 - f1: 0.9847 - val_loss: 0.0400 - val_accuracy: 0.9874 - val_f1: 0.9873\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.0456 - accuracy: 0.9850 - f1: 0.9850 - val_loss: 0.0386 - val_accuracy: 0.9881 - val_f1: 0.9880\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 0.0445 - accuracy: 0.9856 - f1: 0.9855 - val_loss: 0.0378 - val_accuracy: 0.9882 - val_f1: 0.9881\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 0.0435 - accuracy: 0.9859 - f1: 0.9860 - val_loss: 0.0359 - val_accuracy: 0.9894 - val_f1: 0.9894\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.0411 - accuracy: 0.9873 - f1: 0.9873 - val_loss: 0.0322 - val_accuracy: 0.9921 - val_f1: 0.9921\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.0313 - accuracy: 0.9926 - f1: 0.9924 - val_loss: 0.0212 - val_accuracy: 0.9970 - val_f1: 0.9970\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0261 - accuracy: 0.9957 - f1: 0.9958 - val_loss: 0.0165 - val_accuracy: 0.9985 - val_f1: 0.9986\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.0173 - accuracy: 0.9974 - f1: 0.9974 - val_loss: 0.0104 - val_accuracy: 0.9990 - val_f1: 0.9991\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.0114 - accuracy: 0.9981 - f1: 0.9981 - val_loss: 0.0082 - val_accuracy: 0.9993 - val_f1: 0.9994\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 0.0071 - accuracy: 0.9987 - f1: 0.9987 - val_loss: 0.0026 - val_accuracy: 0.9995 - val_f1: 0.9996\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 0.0066 - accuracy: 0.9987 - f1: 0.9988 - val_loss: 0.0032 - val_accuracy: 0.9992 - val_f1: 0.9993\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0059 - accuracy: 0.9988 - f1: 0.9988 - val_loss: 0.0025 - val_accuracy: 0.9994 - val_f1: 0.9994\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0061 - accuracy: 0.9988 - f1: 0.9988 - val_loss: 0.0020 - val_accuracy: 0.9995 - val_f1: 0.9996\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.0045 - accuracy: 0.9992 - f1: 0.9992 - val_loss: 0.0017 - val_accuracy: 0.9995 - val_f1: 0.9996\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0050 - accuracy: 0.9991 - f1: 0.9990 - val_loss: 0.0027 - val_accuracy: 0.9991 - val_f1: 0.9992\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.0054 - accuracy: 0.9990 - f1: 0.9990 - val_loss: 0.0023 - val_accuracy: 0.9993 - val_f1: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# SAME AS NOTEBOOK 7\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "cb = EarlyStopping(monitor='val_loss',\n",
    "                   patience=2,\n",
    "                   restore_best_weights='True',\n",
    "                   mode='min')\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=16,\n",
    "                    verbose=1,\n",
    "                    epochs=100, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at example predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "# SAME AS NOTEBOOK 7\n",
    "predicted_masks = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64, 64, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output has channels where each channel is a class\n",
    "predicted_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x253833aa850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We need to do argmax to get predicted labels\n",
    "i = 2\n",
    "prediction = np.argmax(predicted_masks[i], axis=2)\n",
    "ground_truth = np.argmax(y_val[i], axis=2)\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(X_val[i])\n",
    "ax[1].imshow(ground_truth)\n",
    "ax[2].imshow(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Back to the original shape\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Flow from directory\n",
    "\n",
    "Now this part is also very similar to Notebook 7. The only issue is we need to add the `to_categorical` step.\n",
    "\n",
    "`ImageDataGenerator()` has a parameter called `preprocessing_function` but the documentation says\n",
    "\n",
    ">The function should take one argument: one image (Numpy tensor with rank 3), and should output a Numpy tensor with the same shape.\n",
    "\n",
    "Which means it won't allow `to_categorical` because it changes the shape of the array. So I used a custom generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def custom_generator(dataset_type, batch_size, target_size):\n",
    "    image_datagen = ImageDataGenerator()\n",
    "    mask_datagen = ImageDataGenerator()\n",
    "\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        f'shapes_dataset/{dataset_type}_images',\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        target_size=target_size,\n",
    "        seed=42)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        f'shapes_dataset/{dataset_type}_masks',\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        target_size=target_size,\n",
    "        color_mode='grayscale',\n",
    "        seed=42)\n",
    "    \n",
    "    # Here I can add the to_categorical part\n",
    "    while True:\n",
    "        X = image_generator.next()\n",
    "        Y = mask_generator.next()\n",
    "        Y = to_categorical(Y, num_classes=3)  # Convert masks to categorical\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = custom_generator('train', batch_size=32, target_size=(64, 64))\n",
    "val_gen = custom_generator('val', batch_size=32, target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 64, 64, 16)           448       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 64, 64, 16)           0         ['conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 64, 64, 16)           2320      ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 32, 32, 16)           0         ['conv2d_20[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 32, 32, 32)           4640      ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 32, 32, 32)           0         ['conv2d_21[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 32)           9248      ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 16, 16, 32)           0         ['conv2d_22[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 64)           18496     ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 16, 16, 64)           0         ['conv2d_23[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 64)           36928     ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_24[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 8, 8, 128)            73856     ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 8, 8, 128)            0         ['conv2d_25[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 8, 8, 128)            147584    ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 4, 4, 128)            0         ['conv2d_26[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 4, 4, 256)            295168    ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 4, 4, 256)            0         ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 4, 4, 256)            590080    ['dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 8, 8, 128)            131200    ['conv2d_28[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 8, 8, 256)            0         ['conv2d_transpose_4[0][0]',  \n",
      " )                                                                   'conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 8, 8, 128)            295040    ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 8, 8, 128)            0         ['conv2d_29[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 8, 8, 128)            147584    ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2D  (None, 16, 16, 64)           32832     ['conv2d_30[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 16, 16, 128)          0         ['conv2d_transpose_5[0][0]',  \n",
      " )                                                                   'conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 16, 16, 64)           73792     ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 16, 16, 64)           0         ['conv2d_31[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 16, 16, 64)           36928     ['dropout_15[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2D  (None, 32, 32, 32)           8224      ['conv2d_32[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 32, 32, 64)           0         ['conv2d_transpose_6[0][0]',  \n",
      " )                                                                   'conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 32, 32, 32)           18464     ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 32, 32, 32)           0         ['conv2d_33[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 32, 32, 32)           9248      ['dropout_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2D  (None, 64, 64, 16)           2064      ['conv2d_34[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 64, 64, 32)           0         ['conv2d_transpose_7[0][0]',  \n",
      " )                                                                   'conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 64, 64, 16)           4624      ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 64, 64, 16)           0         ['conv2d_35[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 64, 64, 16)           2320      ['dropout_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 3)            51        ['conv2d_36[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1941139 (7.40 MB)\n",
      "Trainable params: 1941139 (7.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multiclass_unet_model(64, 64, 3, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am cheating here a little\n",
    "# Generators have an attribute to get dataset size\n",
    "# but since I wrote a custom one, I did not implement such attributes\n",
    "# I am simply checking the size from X_train/X_val, but you can check it without loading images to memory\n",
    "num_of_train_images = X_train.shape[0]\n",
    "num_of_val_images = X_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 4.5224 - accuracy: 0.9085 - f1: 0.9079Found 100 images belonging to 1 classes.\n",
      "Found 100 images belonging to 1 classes.\n",
      "15/15 [==============================] - 7s 325ms/step - loss: 4.5224 - accuracy: 0.9085 - f1: 0.9079 - val_loss: 0.5112 - val_accuracy: 0.9689 - val_f1: 0.9632\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 4s 304ms/step - loss: 0.5110 - accuracy: 0.9592 - f1: 0.9589 - val_loss: 0.2223 - val_accuracy: 0.9746 - val_f1: 0.9743\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.2525 - accuracy: 0.9632 - f1: 0.9633 - val_loss: 0.0976 - val_accuracy: 0.9775 - val_f1: 0.9770\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.1674 - accuracy: 0.9638 - f1: 0.9642 - val_loss: 0.0648 - val_accuracy: 0.9792 - val_f1: 0.9788\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.1197 - accuracy: 0.9676 - f1: 0.9686 - val_loss: 0.0447 - val_accuracy: 0.9801 - val_f1: 0.9827\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 0.0869 - accuracy: 0.9721 - f1: 0.9740 - val_loss: 0.0362 - val_accuracy: 0.9810 - val_f1: 0.9847\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 4s 299ms/step - loss: 0.0665 - accuracy: 0.9749 - f1: 0.9779 - val_loss: 0.0298 - val_accuracy: 0.9832 - val_f1: 0.9883\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.0512 - accuracy: 0.9780 - f1: 0.9818 - val_loss: 0.0255 - val_accuracy: 0.9852 - val_f1: 0.9893\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.0423 - accuracy: 0.9801 - f1: 0.9845 - val_loss: 0.0259 - val_accuracy: 0.9832 - val_f1: 0.9886\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.0374 - accuracy: 0.9839 - f1: 0.9862 - val_loss: 0.0208 - val_accuracy: 0.9966 - val_f1: 0.9915\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.0324 - accuracy: 0.9925 - f1: 0.9878 - val_loss: 0.0197 - val_accuracy: 0.9975 - val_f1: 0.9910\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.0302 - accuracy: 0.9937 - f1: 0.9884 - val_loss: 0.0199 - val_accuracy: 0.9975 - val_f1: 0.9912\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.0273 - accuracy: 0.9949 - f1: 0.9895 - val_loss: 0.0178 - val_accuracy: 0.9979 - val_f1: 0.9923\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.0260 - accuracy: 0.9955 - f1: 0.9897 - val_loss: 0.0170 - val_accuracy: 0.9981 - val_f1: 0.9940\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.0243 - accuracy: 0.9961 - f1: 0.9904 - val_loss: 0.0157 - val_accuracy: 0.9986 - val_f1: 0.9927\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.0233 - accuracy: 0.9965 - f1: 0.9905 - val_loss: 0.0157 - val_accuracy: 0.9984 - val_f1: 0.9939\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.0221 - accuracy: 0.9968 - f1: 0.9908 - val_loss: 0.0158 - val_accuracy: 0.9985 - val_f1: 0.9918\n"
     ]
    }
   ],
   "source": [
    "# SAME AS NOTEBOOK 7\n",
    "cb = EarlyStopping(monitor='val_loss',\n",
    "                   patience=2,\n",
    "                   restore_best_weights='True',\n",
    "                   mode='min')\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch = num_of_train_images//32,\n",
    "    epochs=100,\n",
    "    validation_data = val_gen,\n",
    "    validation_steps = num_of_val_images//32,\n",
    "    callbacks=[cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 64, 64, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_masks = model.predict(X_val)\n",
    "predicted_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25383c9a6a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "prediction = np.argmax(predicted_masks[i], axis=2)\n",
    "ground_truth = np.argmax(y_val[i], axis=2)\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(X_val[i])\n",
    "ax[1].imshow(ground_truth)\n",
    "ax[2].imshow(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
